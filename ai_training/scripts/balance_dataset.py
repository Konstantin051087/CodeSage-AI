import json
import os
import random
import re
import time
from collections import Counter
from github import Github
from github.Auth import Token
from tqdm import tqdm
import logging
import argparse
from typing import Dict, List, Optional

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger(__name__)

def collect_sql_injections(max_repos=50, output_dir="ai_training/datasets"):
    """
    –°–æ–±–∏—Ä–∞–µ—Ç –ø—Ä–∏–º–µ—Ä—ã SQL-–∏–Ω—ä–µ–∫—Ü–∏–π –∏–∑ GitHub
    
    Args:
        max_repos: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    
    Returns:
        List[Dict]: –°–ø–∏—Å–æ–∫ —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ SQL-–∏–Ω—ä–µ–∫—Ü–∏–π
    """
    github_token = os.environ.get("GITHUB_TOKEN")
    if not github_token:
        logger.error("GITHUB_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è.")
        logger.error("–¢–æ–∫–µ–Ω –º–æ–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –ø–æ –∞–¥—Ä–µ—Å—É: https://github.com/settings/tokens (—Ç—Ä–µ–±—É—é—Ç—Å—è –ø—Ä–∞–≤–∞ public_repo)")
        return []
    
    try:
        auth = Token(github_token)
        g = Github(auth=auth)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
        user = g.get_user()
        rate_limit = g.get_rate_limit()
        logger.info(f"–ü–æ–¥–∫–ª—é—á–µ–Ω–æ –∫ GitHub API –∫–∞–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {user.login}")
        logger.info(f"–¢–µ–∫—É—â–∏–µ –ª–∏–º–∏—Ç—ã: core: {rate_limit.resources.core.remaining}/{rate_limit.resources.core.limit}, "
                   f"search: {rate_limit.resources.search.remaining}/{rate_limit.resources.search.limit}")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ GitHub API: {str(e)}")
        raise
    
    logger.info("–ù–∞—á–∞–ª–æ —Å–±–æ—Ä–∞ –ø—Ä–∏–º–µ—Ä–æ–≤ —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π...")
    
    # –ë–æ–ª–µ–µ —Ç–æ—á–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ SQL-–∏–Ω—ä–µ–∫—Ü–∏–π
    sql_queries = [
        "sql injection fix in:file language:python",
        "sql injection vulnerability fix in:file language:python",
        "sql injection patch in:file language:python",
        "\"execute(f\\\"\" in:file language:python",
        "\"execute(\" +\" in:file language:python"
    ]
    
    sql_examples = []
    repo_count = 0
    
    for query in sql_queries:
        if repo_count >= max_repos:
            break
            
        logger.info(f"–ü–æ–∏—Å–∫ SQL-–∏–Ω—ä–µ–∫—Ü–∏–π –ø–æ –∑–∞–ø—Ä–æ—Å—É: '{query}'")
        
        try:
            repos = g.search_repositories(query, sort="stars", order="desc")
            
            for repo in tqdm(repos, desc=f"–°–±–æ—Ä —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –ø–æ –∑–∞–ø—Ä–æ—Å—É '{query}'"):
                if repo_count >= max_repos:
                    break
                
                try:
                    logger.debug(f"–ê–Ω–∞–ª–∏–∑ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è: {repo.full_name}")
                    
                    # –ü–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤ —Å –∫–æ–¥–æ–º
                    contents = repo.get_contents("")
                    files_to_check = []
                    processed_paths = set()
                    
                    # –°–Ω–∞—á–∞–ª–∞ —Å–æ–±–∏—Ä–∞–µ–º –≤—Å–µ Python —Ñ–∞–π–ª—ã
                    while contents:
                        file_content = contents.pop(0)
                        if file_content.path in processed_paths:
                            continue
                            
                        processed_paths.add(file_content.path)
                        
                        if file_content.type == "dir" and len(contents) < 100:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –≥–ª—É–±–∏–Ω—É –ø–æ–∏—Å–∫–∞
                            try:
                                contents.extend(repo.get_contents(file_content.path))
                            except Exception as e:
                                continue
                        elif file_content.type == "file" and file_content.path.endswith(".py"):
                            files_to_check.append(file_content)
                    
                    # –ê–Ω–∞–ª–∏–∑ Python —Ñ–∞–π–ª–æ–≤ –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç SQL-—É—è–∑–≤–∏–º–æ—Å—Ç–µ–π
                    for file in files_to_check[:10]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º—ã—Ö —Ñ–∞–π–ª–æ–≤
                        try:
                            file_content = repo.get_contents(file.path).decoded_content.decode('utf-8', errors='ignore')
                            lines = file_content.split('\n')
                            
                            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–∏ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ SQL-–∏–Ω—ä–µ–∫—Ü–∏–π
                            sql_patterns = [
                                r'execute\s*\(\s*f["\'].*\{.*\}.*["\']\s*\)',
                                r'execute\s*\(\s*.*\+.*\)',
                                r'execute\s*\(\s*.*\%.*\)'
                            ]
                            
                            for line_num, line in enumerate(lines, 1):
                                for pattern in sql_patterns:
                                    if re.search(pattern, line, re.IGNORECASE):
                                        # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤–æ–∫—Ä—É–≥ —É—è–∑–≤–∏–º–æ—Å—Ç–∏
                                        context_lines = max(0, line_num - 3), min(len(lines), line_num + 3)
                                        code_context = "\n".join([
                                            f"{i+1}: {lines[i]}" if i+1 != line_num else f"{i+1}: >>> {lines[i].strip()} <<<"
                                            for i in range(context_lines[0], context_lines[1])
                                        ])
                                        
                                        example = {
                                            "repo": repo.full_name,
                                            "file_path": file.path,
                                            "line_number": line_num,
                                            "vulnerability_type": "sql_injection",
                                            "code_snippet": code_context,
                                            "code_before": line.strip(),
                                            "code_after": _get_sql_fix(line.strip()),
                                            "business_impact": "Risk of full database leak ‚Üí GDPR fines up to ‚Ç¨20M",
                                            "fix_recommendation": "Use parameterized queries with placeholders",
                                            "industry_context": "general"
                                        }
                                        sql_examples.append(example)
                                        logger.debug(f"–ù–∞–π–¥–µ–Ω–∞ SQL-–∏–Ω—ä–µ–∫—Ü–∏—è –≤ {repo.full_name}/{file.path}:{line_num}")
                                        break
                        except Exception as e:
                            continue
                
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è {repo.full_name}: {str(e)}")
                    continue
                
                repo_count += 1
                if repo_count >= max_repos:
                    break
                time.sleep(1)  # –£–≤–∞–∂–∞–µ–º –ª–∏–º–∏—Ç—ã GitHub API
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –ø–æ –∑–∞–ø—Ä–æ—Å—É '{query}': {str(e)}")
            continue
    
    # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–∏–º–µ—Ä–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º —à–∞–±–ª–æ–Ω—ã
    if len(sql_examples) < 10:
        logger.warning(f"–°–æ–±—Ä–∞–Ω–æ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ SQL-–ø—Ä–∏–º–µ—Ä–æ–≤ ({len(sql_examples)}). –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤.")
        sql_examples.extend(_generate_synthetic_sql_examples(50 - len(sql_examples)))
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    os.makedirs(output_dir, exist_ok=True)
    output_file = os.path.join(output_dir, "sql_injections.json")
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(sql_examples, f, indent=2, ensure_ascii=False)
    
    logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–æ–±—Ä–∞–Ω–æ {len(sql_examples)} –ø—Ä–∏–º–µ—Ä–æ–≤ SQL-–∏–Ω—ä–µ–∫—Ü–∏–π")
    return sql_examples

def generate_dangerous_functions(count=50, output_dir="ai_training/datasets"):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –Ω–∞–±–æ—Ä –ø—Ä–∏–º–µ—Ä–æ–≤ –æ–ø–∞—Å–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π
    
    Args:
        count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤
        output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    
    Returns:
        List[Dict]: –°–ø–∏—Å–æ–∫ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –æ–ø–∞—Å–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π
    """
    examples = []
    
    # –®–∞–±–ª–æ–Ω—ã –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –æ–ø–∞—Å–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π
    templates = {
        "pickle.loads": [
            {
                "code_before": "data = pickle.loads(user_input)",
                "code_after": "data = json.loads(user_input)",
                "context": "10: import pickle\n11: # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n12: >>> data = pickle.loads(user_input)\n13: process_data(data)",
                "business_impact": "Remote code execution ‚Üí server takeover",
                "fix_recommendation": "Replace with safe alternatives (e.g., json.loads instead of pickle.loads)"
            },
            {
                "code_before": "result = pickle.loads(request.body)",
                "code_after": "result = json.loads(request.body)",
                "context": "5: import pickle\n6: from django.http import HttpRequest\n7: def process_request(request):\n8: >>> result = pickle.loads(request.body)\n9: return HttpResponse(result)",
                "business_impact": "Remote code execution ‚Üí server takeover",
                "fix_recommendation": "Use json.loads() for safe deserialization of JSON data"
            }
        ],
        "eval": [
            {
                "code_before": "result = eval(user_input)",
                "code_after": "result = ast.literal_eval(user_input)",
                "context": "15: import ast\n16: # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n17: >>> result = eval(user_input)\n18: print(f\"Result: {result}\")",
                "business_impact": "Arbitrary code execution ‚Üí complete system compromise",
                "fix_recommendation": "Use ast.literal_eval() for safe evaluation of literals"
            },
            {
                "code_before": "value = eval(f\"{formula}\")",
                "code_after": "value = safe_formula_eval(formula)",
                "context": "22: formula = request.GET.get('formula', 'x+1')\n23: x = 10\n24: >>> value = eval(f\"{formula}\")\n25: return JsonResponse({'result': value})",
                "business_impact": "Arbitrary code execution ‚Üí complete system compromise",
                "fix_recommendation": "Create a safe formula evaluator that only allows mathematical operations"
            }
        ],
        "exec": [
            {
                "code_before": "exec(user_code)",
                "code_after": "# Use a sandboxed execution environment or avoid dynamic execution",
                "context": "30: user_code = request.POST.get('code', '')\n31: # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–æ–¥–∞\n32: >>> exec(user_code)\n33: return render(request, 'result.html', {'status': 'executed'})",
                "business_impact": "Malicious payload execution ‚Üí data theft and service disruption",
                "fix_recommendation": "Avoid exec() ‚Äî refactor to avoid dynamic code execution"
            }
        ],
        "jsonpickle.decode": [
            {
                "code_before": "obj = jsonpickle.decode(json_data)",
                "code_after": "obj = json.loads(json_data)",
                "context": "5: import jsonpickle\n6: # –î–µ—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö\n7: >>> obj = jsonpickle.decode(json_data)\n8: return obj.process()",
                "business_impact": "Object injection ‚Üí arbitrary code execution",
                "fix_recommendation": "Avoid jsonpickle.decode() ‚Äî use standard json module"
            }
        ]
    }
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–º–µ—Ä–æ–≤
    i = 0
    while len(examples) < count:
        for func_type, patterns in templates.items():
            for pattern in patterns:
                if len(examples) >= count:
                    break
                
                example = {
                    "repo": f"synthetic/{func_type}-example-{i}",
                    "file_path": f"utils{i % 3 + 1}.py",
                    "line_number": 15 + (i % 10),
                    "vulnerability_type": "dangerous_function",
                    "function": func_type,
                    "code_snippet": pattern["context"],
                    "code_before": pattern["code_before"],
                    "code_after": pattern["code_after"],
                    "business_impact": pattern["business_impact"],
                    "fix_recommendation": pattern["fix_recommendation"],
                    "industry_context": ["fintech", "healthcare", "ecommerce", "saas", "iot"][i % 5]
                }
                examples.append(example)
                i += 1
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    os.makedirs(output_dir, exist_ok=True)
    output_file = os.path.join(output_dir, "dangerous_functions.json")
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(examples, f, indent=2, ensure_ascii=False)
    
    logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(examples)} –ø—Ä–∏–º–µ—Ä–æ–≤ –æ–ø–∞—Å–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π")
    return examples

def balance_dataset(sql_file="ai_training/datasets/sql_injections.json", 
                   dangerous_file="ai_training/datasets/dangerous_functions.json",
                   output_file="ai_training/datasets/balanced_vulnerabilities.json",
                   test_split=0.2):
    """
    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –∏ –±–∞–ª–∞–Ω—Å–∏—Ä—É–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
    
    Args:
        sql_file: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å SQL-–∏–Ω—ä–µ–∫—Ü–∏—è–º–∏
        dangerous_file: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –æ–ø–∞—Å–Ω—ã–º–∏ —Ñ—É–Ω–∫—Ü–∏—è–º–∏
        output_file: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
        test_split: –î–æ–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    
    Returns:
        Dict: –°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç
    """
    try:
        # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        with open(sql_file, 'r', encoding='utf-8') as f:
            sql_examples = json.load(f)
        
        with open(dangerous_file, 'r', encoding='utf-8') as f:
            dangerous_examples = json.load(f)
        
        logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(sql_examples)} SQL-–∏–Ω—ä–µ–∫—Ü–∏–π –∏ {len(dangerous_examples)} –æ–ø–∞—Å–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π")
        
        # –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤
        min_count = min(len(sql_examples), len(dangerous_examples))
        logger.info(f"–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –±–∞–ª–∞–Ω—Å–∞: {min_count}")
        
        # –°–ª—É—á–∞–π–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ –¥–ª—è –±–∞–ª–∞–Ω—Å–∞
        balanced_sql = random.sample(sql_examples, min_count)
        balanced_dangerous = random.sample(dangerous_examples, min_count)
        
        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        combined_examples = balanced_sql + balanced_dangerous
        
        # –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        random.shuffle(combined_examples)
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
        split_idx = int(len(combined_examples) * (1 - test_split))
        train_examples = combined_examples[:split_idx]
        test_examples = combined_examples[split_idx:]
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
        dataset = {
            "metadata": {
                "total_examples": len(combined_examples),
                "train_examples": len(train_examples),
                "test_examples": len(test_examples),
                "class_distribution": dict(Counter([ex["vulnerability_type"] for ex in combined_examples]))
            },
            "train": train_examples,
            "test": test_examples
        }
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(dataset, f, indent=2, ensure_ascii=False)
        
        logger.info(f"‚úÖ –î–∞—Ç–∞—Å–µ—Ç —É—Å–ø–µ—à–Ω–æ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {output_file}")
        logger.info(f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤: {dataset['metadata']['class_distribution']}")
        logger.info(f"Train/Test split: {len(train_examples)}/{len(test_examples)}")
        
        return dataset
    
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–µ –¥–∞—Ç–∞—Å–µ—Ç–∞: {str(e)}")
        return {}

def _get_sql_fix(vulnerable_line):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–∏–º–µ—Ä –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–ª—è SQL-–∏–Ω—ä–µ–∫—Ü–∏–∏"""
    if "f\"" in vulnerable_line or "f'" in vulnerable_line:
        return "cursor.execute(\"SELECT * FROM users WHERE name = %s\", (name,))"
    elif "+" in vulnerable_line:
        return "cursor.execute(\"SELECT * FROM users WHERE id = %s\", (user_id,))"
    elif "%" in vulnerable_line:
        return "cursor.execute(\"SELECT * FROM users WHERE email = %s\", (email,))"
    else:
        return "cursor.execute(\"SELECT * FROM table WHERE condition = %s\", (value,))"

def _generate_synthetic_sql_examples(count):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã SQL-–∏–Ω—ä–µ–∫—Ü–∏–π"""
    examples = []
    sql_templates = [
        {
            "code_before": "cursor.execute(f\"SELECT * FROM users WHERE name = {name}\")",
            "code_after": "cursor.execute(\"SELECT * FROM users WHERE name = %s\", (name,))",
            "context": "22: def get_user(name):\n23:     # –£—è–∑–≤–∏–º—ã–π –∫–æ–¥\n24: >>> cursor.execute(f\"SELECT * FROM users WHERE name = {name}\")\n25:"
        },
        {
            "code_before": "cursor.execute(\"SELECT * FROM users WHERE id = '\" + user_id + \"'\")", 
            "code_after": "cursor.execute(\"SELECT * FROM users WHERE id = %s\", (user_id,))",
            "context": "10: user_id = request.GET['id']\n11: # –£—è–∑–≤–∏–º—ã–π –∑–∞–ø—Ä–æ—Å\n12: >>> cursor.execute(\"SELECT * FROM users WHERE id = '\" + user_id + \"'\")\n13:"
        },
        {
            "code_before": "query = \"SELECT * FROM products WHERE category = '%s'\" % category",
            "code_after": "query = \"SELECT * FROM products WHERE category = %s\"",
            "context": "5: category = input(\"Enter category: \")\n6: # –ù–µ–±–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ\n7: >>> query = \"SELECT * FROM products WHERE category = '%s'\" % category\n8: cursor.execute(query)"
        },
        {
            "code_before": "cursor.execute(\"SELECT * FROM accounts WHERE balance > \" + str(min_balance))",
            "code_after": "cursor.execute(\"SELECT * FROM accounts WHERE balance > %s\", (min_balance,))",
            "context": "15: min_balance = request.form['min_balance']\n16: # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å –±–µ–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏–∑–∞—Ü–∏–∏\n17: >>> cursor.execute(\"SELECT * FROM accounts WHERE balance > \" + str(min_balance))\n18:"
        }
    ]
    
    for i in range(count):
        template = sql_templates[i % len(sql_templates)]
        example = {
            "repo": f"synthetic/example-{i}",
            "file_path": f"app{i % 4 + 1}.py",
            "line_number": 24 + (i % 5),
            "vulnerability_type": "sql_injection",
            "code_snippet": template["context"],
            "code_before": template["code_before"],
            "code_after": template["code_after"],
            "business_impact": "Risk of full database leak ‚Üí GDPR fines up to ‚Ç¨20M",
            "fix_recommendation": "Use parameterized queries with placeholders",
            "industry_context": ["fintech", "ecommerce", "healthcare", "saas"][i % 4]
        }
        examples.append(example)
    
    return examples

def check_class_balance(dataset_file):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ"""
    try:
        with open(dataset_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # –ï—Å–ª–∏ —ç—Ç–æ —Ñ–∞–π–ª —Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –¥–∞—Ç–∞—Å–µ—Ç–æ–º
        if "train" in data:
            examples = data["train"] + data["test"]
        else:
            examples = data
        
        type_counts = {}
        for item in examples:
            vuln_type = item.get("vulnerability_type", "unknown")
            type_counts[vuln_type] = type_counts.get(vuln_type, 0) + 1
        
        logger.info("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π:")
        total = sum(type_counts.values())
        for vuln_type, count in type_counts.items():
            percentage = (count / total) * 100
            logger.info(f"- {vuln_type}: {count} ({percentage:.1f}%)")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–ª–∞–Ω—Å
        if total > 0 and max(type_counts.values()) / min(type_counts.values()) > 3:
            logger.warning("–î–∞—Ç–∞—Å–µ—Ç –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω. –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏–ª–∏ —Å–±–æ—Ä–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.")
        else:
            logger.info("‚úÖ –î–∞—Ç–∞—Å–µ—Ç —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω –ø–æ –∫–ª–∞—Å—Å–∞–º")
        
        return type_counts
    
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –±–∞–ª–∞–Ω—Å–∞: {str(e)}")
        return {}

def main():
    parser = argparse.ArgumentParser(description='–°–±–æ—Ä, –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è AI-–º–æ–¥–µ–ª–∏')
    parser.add_argument("--max-repos", type=int, default=50, help="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
    parser.add_argument("--dangerous-count", type=int, default=100, help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –æ–ø–∞—Å–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π")
    parser.add_argument("--test-split", type=float, default=0.2, help="–î–æ–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö (0.0-1.0)")
    parser.add_argument("--output-dir", default="ai_training/datasets", help="–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    parser.add_argument("--final-output", default="ai_training/datasets/balanced_vulnerabilities.json", help="–ü—É—Ç—å –∫ –∏—Ç–æ–≥–æ–≤–æ–º—É —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–º—É –¥–∞—Ç–∞—Å–µ—Ç—É")
    parser.add_argument("--skip-github", action="store_true", help="–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∏–∑ GitHub –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
    
    args = parser.parse_args()
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ GITHUB_TOKEN
    if not args.skip_github and not os.environ.get("GITHUB_TOKEN"):
        logger.error("GITHUB_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è:")
        logger.error("export GITHUB_TOKEN=–≤–∞—à_—Ç–æ–∫–µ–Ω_–∑–¥–µ—Å—å")
        logger.error("–¢–æ–∫–µ–Ω –º–æ–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –ø–æ –∞–¥—Ä–µ—Å—É: https://github.com/settings/tokens (—Ç—Ä–µ–±—É—é—Ç—Å—è –ø—Ä–∞–≤–∞ public_repo)")
        logger.info("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ–ª–∞–≥ --skip-github –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ GitHub –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–æ–ª—å–∫–æ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö")
        if not args.skip_github:
            exit(1)
    
    # 1. –°–±–æ—Ä SQL-–∏–Ω—ä–µ–∫—Ü–∏–π
    sql_examples = []
    if not args.skip_github:
        logger.info("üîç –°–±–æ—Ä SQL-–∏–Ω—ä–µ–∫—Ü–∏–π –∏–∑ GitHub...")
        sql_examples = collect_sql_injections(max_repos=args.max_repos, output_dir=args.output_dir)
    else:
        logger.info("‚è≠Ô∏è  –ü—Ä–æ–ø—É—Å–∫ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ GitHub (—Ñ–ª–∞–≥ --skip-github)")
    
    # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –∏–∑ GitHub, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ
    if len(sql_examples) < args.dangerous_count and args.skip_github:
        logger.info("üÜï –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö SQL-–∏–Ω—ä–µ–∫—Ü–∏–π...")
        sql_examples = _generate_synthetic_sql_examples(args.dangerous_count)
    
    # 2. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–ø–∞—Å–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π
    logger.info("üÜï –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–º–µ—Ä–æ–≤ –æ–ø–∞—Å–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π...")
    dangerous_examples = generate_dangerous_functions(count=max(len(sql_examples), args.dangerous_count), output_dir=args.output_dir)
    
    # 3. –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞
    logger.info("‚öñÔ∏è  –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞...")
    sql_file = os.path.join(args.output_dir, "sql_injections.json")
    dangerous_file = os.path.join(args.output_dir, "dangerous_functions.json")
    
    balance_dataset(
        sql_file=sql_file,
        dangerous_file=dangerous_file,
        output_file=args.final_output,
        test_split=args.test_split
    )
    
    # 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∞–ª–∞–Ω—Å–∞
    logger.info("‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –±–∞–ª–∞–Ω—Å–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞...")
    check_class_balance(args.final_output)
    
    logger.info("üéâ –î–∞—Ç–∞—Å–µ—Ç —É—Å–ø–µ—à–Ω–æ —Å–æ–±—Ä–∞–Ω, —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –∏ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω!")
    logger.info(f"–ò—Ç–æ–≥–æ–≤—ã–π —Ñ–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {args.final_output}")

if __name__ == "__main__":
    main()